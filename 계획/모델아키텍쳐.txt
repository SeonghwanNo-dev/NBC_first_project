목표: Knowledge Distillation

1. Teacher Model이 내부에 접근할 수 있는 White box일 때
  - 중간 피처 값들을 모방한다.
  - 마지막 layer의 soft label을 학습한다.

2. Teacher Model이 내부에 접근할 수 없는 Black box일 때
  - Ensemble을 통해 라벨링을 한다.
  - Proxy 기법을 사용한다.

3. Data Augmentation을 이용한 KD <- 어떻게 구현하지.. 해보고 싶긴 해
  - Black box일 때 구현
  - White box일 때 구현
  - DA를 적용했을 때 실제로 성능이 좋아지는가(실제로 좋아지게 계속 연구해야 함...)
